{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time, sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/home/yilingh/SI-Interaction')\n",
    "\n",
    "from selectinf.Simulation.H1.nonlinear_H1_helpers import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T08:46:50.770977Z",
     "start_time": "2025-01-14T08:46:50.537935Z"
    }
   },
   "id": "bd9cb5243d4cd734"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from operator import le, ge\n",
    "def filter_pval_dict_new(target_dict, threshold=0.05, operator=le, p_flag=\"pivot\"):\n",
    "    grouped_targets = pd.DataFrame(target_dict).groupby(['parameter', 'method'])\n",
    "    filtered_dict = {}\n",
    "    # Filter by \n",
    "    for name, group in grouped_targets:\n",
    "        # Subset the selected targets\n",
    "        selected_targets_id = operator(np.abs(group['target']), threshold)\n",
    "        selected_targets = group[p_flag][selected_targets_id]\n",
    "        # Then filtered_dict.keys must be a dictionary\n",
    "        if name[0] in filtered_dict.keys():\n",
    "            filtered_dict[name[0]][name[1]] = selected_targets.tolist()\n",
    "        else:\n",
    "            filtered_dict[name[0]] = {}\n",
    "            filtered_dict[name[0]][name[1]] = selected_targets.tolist()\n",
    "        \n",
    "    return filtered_dict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_MSE(oper_char):\n",
    "    specific_method = \"MLE\"  # Replace with the name of your method\n",
    "    \n",
    "    # Create a modified DataFrame\n",
    "    df_modified = oper_char.copy()\n",
    "    \n",
    "    # For the specific method, keep \"tau\" values separate\n",
    "    # For other methods, set \"tau\" to a single category, e.g., \"All\"\n",
    "    df_modified['prop'] = df_modified.apply(\n",
    "        lambda row: row['prop'] if row['method'] == specific_method else 'Naive/DS', axis=1\n",
    "    )\n",
    "    \n",
    "    # Plotting\n",
    "    sns.boxplot(x='method', y='MSE', hue='prop', data=df_modified, showmeans=True)\n",
    "    plt.xlabel(\"Method\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(\"Boxplot of MSE by Method and prop\")\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T08:46:50.780919Z",
     "start_time": "2025-01-14T08:46:50.778736Z"
    }
   },
   "id": "bd5174116d530eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simulation: vary correlation between features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a20d1f8342eb4e77"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def predict(beta_hat, X_test):\n",
    "    return X_test.dot(beta_hat)\n",
    "\n",
    "def generate_test(Y_mean, noise_sd):\n",
    "    n = Y_mean.shape[0]\n",
    "    Y_test = Y_mean + np.random.normal(size=(n,), scale=noise_sd)\n",
    "    \n",
    "    return Y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T08:46:50.949958Z",
     "start_time": "2025-01-14T08:46:50.947187Z"
    }
   },
   "id": "e5ecb73a78765aa0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)\n",
    "# Generating active interactions\n",
    "active_inter_list_true = np.array([[0,1], [1,2], [2,4], [1,5], [2,6]])\n",
    "targeting_sizes = [0, 5, 10, 15]\n",
    "active_inter_dict = {}\n",
    "active_inter_list_dict = {}\n",
    "for size in targeting_sizes:\n",
    "    active_inter_dict[size] = active_inter_list_true.copy()\n",
    "    active_inter_list_dict[size] = [(x[0],x[1]) for x in active_inter_list_true]\n",
    "    for i in range(size):\n",
    "        sampled = False\n",
    "        while not sampled:\n",
    "            # sample first covariate\n",
    "            j = random.sample([0,1,2], k=1)[0]\n",
    "            # sample second covariate\n",
    "            k = random.sample(list(range(3,20)), k=1)[0]\n",
    "            if (j,k) not in active_inter_list_dict[size]:\n",
    "                active_inter_dict[size] = np.concatenate((active_inter_dict[size],\n",
    "                                                               np.array([[j,k]])), axis=0)\n",
    "                active_inter_list_dict[size].append((j,k))\n",
    "                sampled = True\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T08:46:52.071611Z",
     "start_time": "2025-01-14T08:46:52.066983Z"
    }
   },
   "id": "e3e69e264af813e4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0 th simulation done\n",
      "seed: 1000\n",
      "Equally spaced quantile knots used.\n",
      "Main: 1.4617371685425304\n",
      "Interaction: 4.543317099148506\n",
      "induced SNR: 8.048062398534743\n",
      "SD(Y):  6.1672878702312905\n",
      "Naive Selected Groups: 7\n",
      "DS Selected Groups: 8\n",
      "Data Carving Randomization Used\n",
      "MLE Selected Groups: 5\n",
      "15 1 th simulation done\n",
      "seed: 1001\n",
      "Equally spaced quantile knots used.\n",
      "Main: 1.3638875363070908\n",
      "Interaction: 4.27349719124621\n",
      "induced SNR: 7.097445564793671\n",
      "SD(Y):  5.479835513457365\n",
      "Naive Selected Groups: 9\n",
      "DS Selected Groups: 9\n",
      "Data Carving Randomization Used\n",
      "MLE Selected Groups: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 183\u001B[0m\n\u001B[1;32m    171\u001B[0m     update_targets(\u001B[38;5;28mdict\u001B[39m\u001B[38;5;241m=\u001B[39mtarget_dict,\n\u001B[1;32m    172\u001B[0m                    true_inter_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    173\u001B[0m                    targets\u001B[38;5;241m=\u001B[39mtargets_ds, parameter\u001B[38;5;241m=\u001B[39msize,\n\u001B[1;32m    174\u001B[0m                    method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData Splitting\u001B[39m\u001B[38;5;124m\"\u001B[39m, idx\u001B[38;5;241m=\u001B[39midx_ds,\n\u001B[1;32m    175\u001B[0m                        pvals\u001B[38;5;241m=\u001B[39mp_values_ds,\n\u001B[1;32m    176\u001B[0m                        pivots\u001B[38;5;241m=\u001B[39mpivots_ds, sim_idx\u001B[38;5;241m=\u001B[39mi)\n\u001B[1;32m    178\u001B[0m \u001B[38;5;66;03m# Continue if data splitting yields a nonempty group lasso selection\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;66;03m# (this is almost always the case)    \u001B[39;00m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;66;03m# Performing MLE using 'all pairs'\u001B[39;00m\n\u001B[1;32m    181\u001B[0m (coverages_MLE, lengths_MLE, selected_inter_MLE, p_values_MLE, \n\u001B[1;32m    182\u001B[0m  pivots_MLE, targets_MLE, idx_MLE, beta_hat_MLE)\\\n\u001B[0;32m--> 183\u001B[0m     \u001B[38;5;241m=\u001B[39m (\u001B[43mMLE_inference_inter\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m       \u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesign\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_mean\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp_nl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minteractions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_interaction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43mintercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m#randomizer_sd_const=tau, \u001B[39;49;00m\n\u001B[1;32m    188\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproportion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_frac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.9\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweakhierarchy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msolve_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontinued\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparallel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot_n_scaled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mroot_n_scaled\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    194\u001B[0m noselection_MLE \u001B[38;5;241m=\u001B[39m coverages_MLE \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# Collect results if all three methods yields \u001B[39;00m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# nonempty first-stage selection\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/Simulation/simulation_helpers.py:895\u001B[0m, in \u001B[0;36mMLE_inference_inter\u001B[0;34m(X, Y, Y_mean, groups, n_features, interactions, intercept, weight_frac, level, proportion, mode, parallel, continued, solve_only, conv_cont, nonzero_cont, ncores, p_val, return_pivot, target_ids, randomizer_sd_const, root_n_scaled)\u001B[0m\n\u001B[1;32m    887\u001B[0m         coverages, lengths, selected_interactions, targets \\\n\u001B[1;32m    888\u001B[0m             \u001B[38;5;241m=\u001B[39m interaction_selective_tests_all(conv, dispersion,\n\u001B[1;32m    889\u001B[0m                                               X_E, Y_mean, n_features, active_vars_flag,\n\u001B[1;32m    890\u001B[0m                                               interactions,\n\u001B[1;32m    891\u001B[0m                                               level\u001B[38;5;241m=\u001B[39mlevel, mode\u001B[38;5;241m=\u001B[39mmode, p_val\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    892\u001B[0m                                               target_ids\u001B[38;5;241m=\u001B[39mtarget_ids)\n\u001B[1;32m    893\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    894\u001B[0m         coverages, lengths, selected_interactions, p_values, pivots, targets \\\n\u001B[0;32m--> 895\u001B[0m             \u001B[38;5;241m=\u001B[39m \u001B[43minteraction_selective_tests_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdispersion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43mX_E\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_mean\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactive_vars_flag\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43minteractions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    898\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    899\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43mreturn_pivot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_pivot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    900\u001B[0m \u001B[43m                                              \u001B[49m\u001B[43mtarget_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m p_val:\n\u001B[1;32m    903\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (coverages, lengths, selected_interactions,\n\u001B[1;32m    904\u001B[0m             targets, task_idx, soln)\u001B[38;5;66;03m#target_ids\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/Simulation/simulation_helpers.py:678\u001B[0m, in \u001B[0;36minteraction_selective_tests_all\u001B[0;34m(conv, dispersion, X_E, Y_mean, n_features, active_vars_flag, interactions, level, mode, p_val, return_pivot, target_ids)\u001B[0m\n\u001B[1;32m    673\u001B[0m     coverage, length, selected, target \\\n\u001B[1;32m    674\u001B[0m         \u001B[38;5;241m=\u001B[39m interaction_selective_single(conv, dispersion, X_E, Y_mean,\n\u001B[1;32m    675\u001B[0m                                        interaction_ij, level\u001B[38;5;241m=\u001B[39mlevel, p_val\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    676\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    677\u001B[0m     coverage, length, selected, p_inter, pivots, target \\\n\u001B[0;32m--> 678\u001B[0m         \u001B[38;5;241m=\u001B[39m \u001B[43minteraction_selective_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdispersion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_E\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_mean\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43minteraction_ij\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m                                       \u001B[49m\u001B[43mreturn_pivot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_pivot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m     p_values_list\u001B[38;5;241m.\u001B[39mappend(p_inter)\n\u001B[1;32m    682\u001B[0m     pivots_list\u001B[38;5;241m.\u001B[39mappend(pivots)\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/Simulation/simulation_helpers.py:568\u001B[0m, in \u001B[0;36minteraction_selective_single\u001B[0;34m(conv, dispersion, X_E, Y_mean, interaction, level, p_val, return_pivot)\u001B[0m\n\u001B[1;32m    561\u001B[0m conv\u001B[38;5;241m.\u001B[39msetup_inference(dispersion\u001B[38;5;241m=\u001B[39mdispersion)\n\u001B[1;32m    563\u001B[0m target_spec \u001B[38;5;241m=\u001B[39m selected_targets_interaction(conv\u001B[38;5;241m.\u001B[39mloglike,\n\u001B[1;32m    564\u001B[0m                                            conv\u001B[38;5;241m.\u001B[39mobserved_soln,\n\u001B[1;32m    565\u001B[0m                                            leastsq\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    566\u001B[0m                                            interaction\u001B[38;5;241m=\u001B[39minteraction,\n\u001B[1;32m    567\u001B[0m                                            dispersion\u001B[38;5;241m=\u001B[39mdispersion)\n\u001B[0;32m--> 568\u001B[0m result, _ \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_spec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    569\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mselective_MLE\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    570\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p_val:\n\u001B[1;32m    573\u001B[0m     pval \u001B[38;5;241m=\u001B[39m result[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpvalue\u001B[39m\u001B[38;5;124m'\u001B[39m][p_prime \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/query_jacobian.py:255\u001B[0m, in \u001B[0;36mgaussian_query.inference\u001B[0;34m(self, target_spec, method, level, method_args)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    249\u001B[0m     G \u001B[38;5;241m=\u001B[39m mle_inference(query_spec,\n\u001B[1;32m    250\u001B[0m                       target_spec,\n\u001B[1;32m    251\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39museJacobian,\n\u001B[1;32m    252\u001B[0m                       \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    253\u001B[0m                       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmethod_args)\n\u001B[0;32m--> 255\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mG\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolve_estimating_eqn\u001B[49m\u001B[43m(\u001B[49m\u001B[43malternatives\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_spec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43malternatives\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m2\u001B[39m]\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/selective_MLE_jacobian.py:78\u001B[0m, in \u001B[0;36mmle_inference.solve_estimating_eqn\u001B[0;34m(self, alternatives, useC, level)\u001B[0m\n\u001B[1;32m     71\u001B[0m     val, soln, hess \u001B[38;5;241m=\u001B[39m solver(conjugate_arg,\n\u001B[1;32m     72\u001B[0m                              cond_precision,\n\u001B[1;32m     73\u001B[0m                              QS\u001B[38;5;241m.\u001B[39mobserved_soln,\n\u001B[1;32m     74\u001B[0m                              QS\u001B[38;5;241m.\u001B[39mlinear_part,\n\u001B[1;32m     75\u001B[0m                              QS\u001B[38;5;241m.\u001B[39moffset,\n\u001B[1;32m     76\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolve_args)\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 78\u001B[0m     val, soln, hess \u001B[38;5;241m=\u001B[39m \u001B[43msolve_barrier_affine_jacobian_py\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconjugate_arg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mcond_precision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mQS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobserved_soln\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mQS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_part\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mQS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mJS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# for Jacobian\u001B[39;49;00m\n\u001B[1;32m     84\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43mJS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mactive_dirs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[43museJacobian\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m                                                       \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolve_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m# Everything below this line are unchanged and apply to both the Lasso and group Lasso\u001B[39;00m\n\u001B[1;32m     89\u001B[0m final_estimator \u001B[38;5;241m=\u001B[39m TS\u001B[38;5;241m.\u001B[39mcov_target\u001B[38;5;241m.\u001B[39mdot(prec_target_nosel)\u001B[38;5;241m.\u001B[39mdot(TS\u001B[38;5;241m.\u001B[39mobserved_target) \\\n\u001B[1;32m     90\u001B[0m                   \u001B[38;5;241m+\u001B[39m TS\u001B[38;5;241m.\u001B[39mregress_target_score\u001B[38;5;241m.\u001B[39mdot(QS\u001B[38;5;241m.\u001B[39mM1\u001B[38;5;241m.\u001B[39mdot(QS\u001B[38;5;241m.\u001B[39mopt_linear))\u001B[38;5;241m.\u001B[39mdot(QS\u001B[38;5;241m.\u001B[39mcond_mean \u001B[38;5;241m-\u001B[39m soln) \\\n\u001B[1;32m     91\u001B[0m                   \u001B[38;5;241m-\u001B[39m bias_target\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/selective_MLE_jacobian.py:199\u001B[0m, in \u001B[0;36msolve_barrier_affine_jacobian_py\u001B[0;34m(conjugate_arg, precision, feasible_point, con_linear, con_offset, C, active_dirs, useJacobian, step, nstep, min_its, tol)\u001B[0m\n\u001B[1;32m    196\u001B[0m current_value \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39minf\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m itercount \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(nstep):\n\u001B[0;32m--> 199\u001B[0m     cur_grad \u001B[38;5;241m=\u001B[39m \u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;66;03m# make sure proposal is feasible\u001B[39;00m\n\u001B[1;32m    203\u001B[0m     count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/selective_MLE_jacobian.py:180\u001B[0m, in \u001B[0;36msolve_barrier_affine_jacobian_py.<locals>.grad\u001B[0;34m(gs)\u001B[0m\n\u001B[1;32m    178\u001B[0m p2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39mcon_linear\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;241m1.\u001B[39m \u001B[38;5;241m/\u001B[39m (scaling \u001B[38;5;241m+\u001B[39m con_offset \u001B[38;5;241m-\u001B[39m con_linear\u001B[38;5;241m.\u001B[39mdot(gs)))\n\u001B[1;32m    179\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m useJacobian:\n\u001B[0;32m--> 180\u001B[0m     p3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[43mjacobian_grad_hess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactive_dirs\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    182\u001B[0m     p3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/selective_MLE_jacobian.py:258\u001B[0m, in \u001B[0;36mjacobian_grad_hess\u001B[0;34m(gamma, C, active_dirs)\u001B[0m\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 258\u001B[0m     GammaMinus \u001B[38;5;241m=\u001B[39m \u001B[43mcalc_GammaMinus\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactive_dirs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# eigendecomposition\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;66;03m#evalues, evectors = eig(GammaMinus + C)\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \n\u001B[1;32m    263\u001B[0m     \u001B[38;5;66;03m# log Jacobian\u001B[39;00m\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;66;03m#J = log(evalues).sum()\u001B[39;00m\n\u001B[1;32m    265\u001B[0m     J \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlog(np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mdet(GammaMinus \u001B[38;5;241m+\u001B[39m C))\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/selectinf/selective_MLE_jacobian.py:249\u001B[0m, in \u001B[0;36mcalc_GammaMinus\u001B[0;34m(gamma, active_dirs)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Calculate Gamma^minus (as a function of gamma vector, active directions)\u001B[39;00m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    248\u001B[0m to_diag \u001B[38;5;241m=\u001B[39m [[g] \u001B[38;5;241m*\u001B[39m (ug\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m (g, ug) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(gamma, active_dirs\u001B[38;5;241m.\u001B[39mvalues())]\n\u001B[0;32m--> 249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mblock_diag\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mto_diag\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgp\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/SI-Interaction/env3/lib/python3.9/site-packages/scipy/linalg/_special_matrices.py:561\u001B[0m, in \u001B[0;36mblock_diag\u001B[0;34m(*arrs)\u001B[0m\n\u001B[1;32m    557\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marguments in the following positions have dimension \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    558\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgreater than 2: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m bad_args)\n\u001B[1;32m    560\u001B[0m shapes \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([a\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m arrs])\n\u001B[0;32m--> 561\u001B[0m out_dtype \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43marr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43marr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43marrs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    562\u001B[0m out \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(np\u001B[38;5;241m.\u001B[39msum(shapes, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), dtype\u001B[38;5;241m=\u001B[39mout_dtype)\n\u001B[1;32m    564\u001B[0m r, c \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mresult_type\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# A dictionary recording simulation results and metrics\n",
    "oper_char = {}\n",
    "oper_char[\"coverage rate\"] = []\n",
    "oper_char[\"avg length\"] = []\n",
    "oper_char[\"method\"] = []\n",
    "#oper_char[\"MSE\"] = []\n",
    "oper_char[\"prop\"] = []\n",
    "oper_char[\"size\"] = []\n",
    "oper_char[\"signal\"] = []\n",
    "oper_char[\"main signal\"] = []\n",
    "oper_char[\"target\"] = []\n",
    "oper_char[\"power\"] = []\n",
    "\n",
    "MSE_dict = {}\n",
    "MSE_dict[\"MSE\"] = []\n",
    "MSE_dict[\"method\"] = []\n",
    "MSE_dict[\"size\"] = []\n",
    "\n",
    "# Dictionary of projected targets, over all simulation parameters\n",
    "target_dict = {}\n",
    "target_dict[\"parameter\"] = []\n",
    "target_dict[\"target\"] = []\n",
    "target_dict[\"target id\"] = []\n",
    "target_dict[\"method\"] = []\n",
    "target_dict[\"index\"] = []\n",
    "target_dict[\"pivot\"] = []\n",
    "target_dict[\"pval\"] = []\n",
    "\n",
    "# A dictionary recording p-values for each true interaction\n",
    "# over all simulation results.\n",
    "# Each simulation parameter (here parameter_list contain a list of main signal strengths \n",
    "# to be considered) has a corresponding dictionary of results\n",
    "parameter_list = np.array([15])#np.array(targeting_sizes)\n",
    "pval_dict = {}\n",
    "for x in parameter_list:\n",
    "    pval_dict[x] = {}\n",
    "    for m in ['Naive', 'Data Splitting', 'MLE']:\n",
    "        pval_dict[x][m] = []\n",
    "\n",
    "# Group lasso solver constructor\n",
    "const = group_lasso.gaussian\n",
    "\n",
    "rho = 0.5 # Correlation of signal covariates (amongst themselves), and noise.\n",
    "sig = 1  # Controlling interaction vs main signals. \n",
    "           # Setting it this way generates comparable main \n",
    "           # and interaction signals (sig = 2 works )\n",
    "weights = 0.3 # Group Lasso weights\n",
    "s_inter = 5 # Number of true interactions\n",
    "p_nl = 20 # Number of nonlinear covariates\n",
    "n=200\n",
    "root_n_scaled = False\n",
    "main_sig = 2\n",
    "prop=0.9\n",
    "\n",
    "\n",
    "ds_rank_def_count = {size: 0 for size in parameter_list}\n",
    "\n",
    "for size in parameter_list:\n",
    "    for i in range(10):\n",
    "        np.random.seed(i+1000)\n",
    "        #MSE_set = False\n",
    "        \n",
    "        print(size, i,\"th simulation done\")\n",
    "        print(\"seed:\", i+1000)\n",
    "        # Generating a (X, Y) pair, and corresponding basis expansion\n",
    "        # The 'weakhierarchy' argument is overridden by setting \n",
    "        # `active_inter_list`.\n",
    "        (design, data_interaction, Y, Y_mean, data_combined,\n",
    "         groups, active, active_inter_adj, active_inter_list, gamma) \\\n",
    "            = (generate_gaussian_instance_nonlinear_interaction_simple\n",
    "               (n=n, p_nl=p_nl, rho=rho, full_corr=False,\n",
    "                rho_noise=rho, block_corr=True, rho_cross=rho,\n",
    "                SNR = None, main_signal=main_sig, noise_sd=2,\n",
    "                nknots = 6, degree = 2, interaction_signal=sig,\n",
    "                random_signs=False, scale=root_n_scaled, center=False,\n",
    "                structure='weakhierarchy', s_interaction=size+5,\n",
    "                intercept=True, active_inter_list=active_inter_dict[size], \n",
    "                return_gamma=True))\n",
    "        print(\"SD(Y): \", np.std(Y))\n",
    "        Y_test = Y_mean + np.random.normal(size=(n,), scale=2)\n",
    "        \n",
    "        # Performing Naive inference using 'all pairs'\n",
    "        (coverages, lengths, selected_inter, p_values, pivots, targets, idx, \n",
    "        beta_hat_naive) \\\n",
    "            = naive_inference_inter(X=design, Y=Y, groups=groups,\n",
    "                                    Y_mean=Y_mean, const=const,\n",
    "                                    n_features=20, interactions=data_interaction,\n",
    "                                    weight_frac=weights, level=0.9, mode='weakhierarchy',\n",
    "                                    solve_only=False, continued=False,\n",
    "                                    parallel=False, p_val=True, \n",
    "                                    return_pivot=True, intercept=True, \n",
    "                                    target_ids=None,\n",
    "                                       root_n_scaled=root_n_scaled)\n",
    "        \n",
    "        noselection_naive = coverages is None\n",
    "        \n",
    "        if not noselection_naive:\n",
    "            # Naive\n",
    "            oper_char[\"coverage rate\"].append(np.mean(coverages))\n",
    "            oper_char[\"avg length\"].append(np.mean(lengths))\n",
    "            oper_char[\"method\"].append('Naive')\n",
    "            oper_char[\"signal\"].append(sig)\n",
    "            oper_char[\"main signal\"].append(main_sig)\n",
    "            oper_char[\"prop\"].append(prop)\n",
    "            oper_char[\"size\"].append(size)\n",
    "            #oper_char[\"MSE\"].append(MSE_naive)\n",
    "            #oper_char[\"SNR\"].append(SNR)\n",
    "            oper_char[\"target\"].append(targets[0])\n",
    "            pval_dict[size]['Naive'] += (p_values)\n",
    "            oper_char[\"power\"].append(calculate_power(p_values, targets, 0.1))\n",
    "            update_targets(dict=target_dict,\n",
    "                           true_inter_list=None,\n",
    "                           targets=targets, parameter=size,\n",
    "                           method=\"Naive\", idx=idx,\n",
    "                           pvals=p_values,\n",
    "                           pivots=pivots, sim_idx=i)\n",
    "          \n",
    "        # Continue if Naive yields a nonempty group lasso selection\n",
    "        # (this is almost always the case)\n",
    "        # Performing data splitting using 'all pairs'\n",
    "        # DS solve only\n",
    "        ds_rank_def = False\n",
    "        (nonzero_ds, selected_groups_ds, subset_select_ds, beta_hat_ds) \\\n",
    "            = data_splitting_inter(X=design, Y=Y, groups=groups,\n",
    "                                   Y_mean=Y_mean, const=const,\n",
    "                                   n_features=20, interactions=data_interaction,\n",
    "                                   proportion=prop,\n",
    "                                   weight_frac=weights, level=0.9,\n",
    "                                   mode='weakhierarchy',\n",
    "                                   solve_only=True, continued=False,\n",
    "                                   parallel=False, p_val=True,\n",
    "                                   target_ids=None,\n",
    "                                   root_n_scaled=root_n_scaled)\n",
    "        if nonzero_ds.sum() + 1 >= n-subset_select_ds.sum():\n",
    "            ds_rank_def = True\n",
    "            ds_rank_def_count[size] += 1\n",
    "\n",
    "        if not ds_rank_def:\n",
    "            (coverages_ds, lengths_ds, selected_inter_ds,\n",
    "             p_values_ds, pivots_ds, targets_ds, idx_ds, beta_hat_ds) \\\n",
    "                = data_splitting_inter(X=design, Y=Y, groups=groups,\n",
    "                                       Y_mean=Y_mean, const=const,\n",
    "                                       n_features=20, interactions=data_interaction,\n",
    "                                       proportion=prop,\n",
    "                                       weight_frac=weights, level=0.9,\n",
    "                                       mode='weakhierarchy',\n",
    "                                       solve_only=False, continued=True,\n",
    "                                       parallel=False, p_val=True,\n",
    "                                       target_ids=None,\n",
    "                                       root_n_scaled=root_n_scaled,\n",
    "                                       subset_cont=subset_select_ds,\n",
    "                                       nonzero_cont=nonzero_ds,\n",
    "                                       selected_groups_cont=selected_groups_ds,\n",
    "                                       soln_cont=beta_hat_ds)\n",
    "            noselection_ds = coverages_ds is None\n",
    "        \n",
    "        if not ds_rank_def and not noselection_ds:\n",
    "            # Data splitting\n",
    "            oper_char[\"coverage rate\"].append(np.mean(coverages_ds))\n",
    "            oper_char[\"avg length\"].append(np.mean(lengths_ds))\n",
    "            oper_char[\"method\"].append('Data Splitting')\n",
    "            oper_char[\"signal\"].append(sig)\n",
    "            oper_char[\"main signal\"].append(main_sig)\n",
    "            oper_char[\"prop\"].append(prop)\n",
    "            oper_char[\"size\"].append(size)\n",
    "            #oper_char[\"MSE\"].append(MSE_ds)\n",
    "            #oper_char[\"SNR\"].append(SNR)\n",
    "            oper_char[\"target\"].append(targets_ds[0])\n",
    "            pval_dict[size]['Data Splitting'] += (p_values_ds)\n",
    "            oper_char[\"power\"].append(calculate_power(p_values_ds, targets_ds, 0.1))\n",
    "            update_targets(dict=target_dict,\n",
    "                           true_inter_list=None,\n",
    "                           targets=targets_ds, parameter=size,\n",
    "                           method=\"Data Splitting\", idx=idx_ds,\n",
    "                               pvals=p_values_ds,\n",
    "                               pivots=pivots_ds, sim_idx=i)\n",
    "        \n",
    "        # Continue if data splitting yields a nonempty group lasso selection\n",
    "        # (this is almost always the case)    \n",
    "        # Performing MLE using 'all pairs'\n",
    "        (coverages_MLE, lengths_MLE, selected_inter_MLE, p_values_MLE, \n",
    "         pivots_MLE, targets_MLE, idx_MLE, beta_hat_MLE)\\\n",
    "            = (MLE_inference_inter\n",
    "               (X=design, Y=Y, Y_mean=Y_mean, groups=groups,\n",
    "                n_features=p_nl, interactions=data_interaction,\n",
    "                intercept=True, \n",
    "                #randomizer_sd_const=tau, \n",
    "                proportion=prop,\n",
    "                weight_frac=weights,\n",
    "                level=0.9, mode='weakhierarchy', solve_only=False, \n",
    "                continued=False, parallel=False, p_val=True, \n",
    "                target_ids=None,\n",
    "                root_n_scaled=root_n_scaled))\n",
    "        noselection_MLE = coverages_MLE is None\n",
    "        \n",
    "        # Collect results if all three methods yields \n",
    "        # nonempty first-stage selection\n",
    "        if not noselection_MLE:\n",
    "            # MLE\n",
    "            oper_char[\"coverage rate\"].append(np.mean(coverages_MLE))\n",
    "            oper_char[\"avg length\"].append(np.mean(lengths_MLE))\n",
    "            oper_char[\"method\"].append('MLE')\n",
    "            oper_char[\"signal\"].append(sig)\n",
    "            oper_char[\"main signal\"].append(main_sig)\n",
    "            oper_char[\"prop\"].append(prop)\n",
    "            oper_char[\"size\"].append(size)\n",
    "            #oper_char[\"MSE\"].append(MSE_MLE)\n",
    "            #oper_char[\"SNR\"].append(SNR)\n",
    "            oper_char[\"target\"].append(targets_MLE[0])\n",
    "            pval_dict[size]['MLE'] += (p_values_MLE)\n",
    "            oper_char[\"power\"].append(calculate_power(p_values_MLE, \n",
    "                                                      targets_MLE,\n",
    "                                                      0.1))\n",
    "            update_targets(dict=target_dict,\n",
    "                           true_inter_list=None,\n",
    "                           targets=targets_MLE, parameter=size,\n",
    "                           method=\"MLE\", idx=idx_MLE,\n",
    "                               pvals=p_values_MLE,\n",
    "                               pivots=pivots_MLE, sim_idx=i)\n",
    "        \n",
    "        # Set MSE  \n",
    "        MSE_naive = np.mean((Y_test - predict(beta_hat_naive, design))**2)\n",
    "        MSE_dict[\"MSE\"].append(MSE_naive)\n",
    "        MSE_dict[\"method\"].append(\"Naive\")\n",
    "        MSE_dict[\"size\"].append(size)\n",
    "        \n",
    "        MSE_ds = np.mean((Y_test - predict(beta_hat_ds, design))**2)\n",
    "        MSE_dict[\"MSE\"].append(MSE_ds)\n",
    "        MSE_dict[\"method\"].append(\"Data Splitting\")\n",
    "        MSE_dict[\"size\"].append(size)\n",
    "        \n",
    "        MSE_MLE = np.mean((Y_test - predict(beta_hat_MLE, design))**2)\n",
    "        MSE_dict[\"MSE\"].append(MSE_MLE)\n",
    "        MSE_dict[\"method\"].append(\"MLE\")\n",
    "        MSE_dict[\"size\"].append(size)\n",
    "        MSE_set = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T06:59:04.613973Z",
     "start_time": "2025-01-11T06:58:50.481809Z"
    }
   },
   "id": "57519f76e79ac826"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'aa_0_1'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = 'aa'\n",
    "start = 0\n",
    "end = 1\n",
    "f'{dir}_{start}_{end}'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T19:49:01.254676Z",
     "start_time": "2024-12-12T19:49:01.247767Z"
    }
   },
   "id": "e4ead07045bf16da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump([ds_rank_def_count, target_dict, pval_dict, MSE_dict, oper_char],\n",
    "            f'vary_sparsity_{prop}.pkl', compress=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-12T07:12:06.604442Z",
     "start_time": "2024-12-12T07:12:06.603965Z"
    }
   },
   "id": "f5068efe6b953632"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import joblib\n",
    "ds_rank_def_count, target_dict, pval_dict, MSE_dict, oper_char = joblib.load('vary_sparsity_0.9.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.605559Z"
    }
   },
   "id": "d4b368868df219da"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "{20: 1}"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_rank_def_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-11T06:56:51.934288Z",
     "start_time": "2025-01-11T06:56:51.918061Z"
    }
   },
   "id": "6f5451ec49d7a332"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ds_rank_def_count, target_dict, pval_dict, MSE_dict, oper_char = joblib.load('toy_weak.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.608763Z"
    }
   },
   "id": "1949ec954780c461"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds_rank_def_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.610333Z"
    }
   },
   "id": "a640718041c6348f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ecdfs(pval_dict, xaxis=\"$'rho'$\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.611846Z"
    }
   },
   "id": "396354227eb61cef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Plotting dict: SNR - Method - List of pvals\n",
    "## Plotting dict: SNR - Method - List of pvals\n",
    "filtered_dict = filter_pval_dict_new(target_dict, threshold = 0,\n",
    "                                     operator=ge)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.613345Z"
    }
   },
   "id": "bf992c3bcda1c17d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_ecdfs(filtered_dict, xaxis=r\"$\\rho_{cross}$\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.615678Z"
    }
   },
   "id": "962346b64f8b15cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_palette = {\"MLE\": \"#48c072\",\n",
    "                  \"Naive\": \"#fc5a50\",\n",
    "                  \"Data Splitting\": \"#03719c\"}\n",
    "sns.set_style(\"white\", {'axes.facecolor': 'white',\n",
    "                            'axes.grid': True,\n",
    "                            'axes.linewidth': 2.0,\n",
    "                            'grid.linestyle': u'--',\n",
    "                            'grid.linewidth': 4.0,\n",
    "                            'xtick.major.size': 5.0,\n",
    "                            })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.617923Z"
    }
   },
   "id": "18ad1b3efe0eaac9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pointplot(x=pd.DataFrame(oper_char)[\"rho\"],\n",
    "              y=pd.DataFrame(oper_char)[\"avg length\"],\n",
    "              hue=pd.DataFrame(oper_char)[\"method\"], markers='o',\n",
    "              palette=my_palette)\n",
    "#plt.ylim(10,35)\n",
    "plt.xlabel(r\"$\\rho_{cross}$\")\n",
    "plt.ylabel(\"Average Length\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.619581Z"
    }
   },
   "id": "4679b354f2765806"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.pointplot(x=pd.DataFrame(MSE_dict)[\"rho\"],\n",
    "              y=pd.DataFrame(MSE_dict)[\"MSE\"],\n",
    "              hue=pd.DataFrame(MSE_dict)[\"method\"], markers='o',\n",
    "              palette=my_palette)\n",
    "#plt.ylim(25,30)\n",
    "plt.xlabel(r\"$\\rho_{cross}$\")\n",
    "plt.ylabel(\"Test MSE\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.621249Z"
    }
   },
   "id": "20c452f78aa85942"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Applying BY Correction to the p-values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98486f1d9c30f876"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from scipy.stats import false_discovery_control\n",
    "\n",
    "\n",
    "def add_BY_pval_by_method_and_index(data):\n",
    "    # Check if BYpval is there\n",
    "    if \"BYpval\" in data.keys():\n",
    "        return\n",
    "    # Assuming your dictionary is named 'data' and structured as described\n",
    "    methods = data['method']\n",
    "    indices = data['index']\n",
    "    pvals = data['pval']\n",
    "\n",
    "    # Initialize default dictionaries to collect p-values and positions for each (method, index) pair\n",
    "    pvals_dict = defaultdict(list)\n",
    "    pos_dict = defaultdict(list)\n",
    "\n",
    "    # Iterate over the data and populate the dictionaries\n",
    "    for i, (method, index, pval) in enumerate(zip(methods, indices, pvals)):\n",
    "        key = (method, index)\n",
    "        pvals_dict[key].append(pval)\n",
    "        pos_dict[key].append(i)\n",
    "\n",
    "    # Initialize BYpvals array with the same length as pvals\n",
    "    BYpvals = [0] * len(pvals)  # or use numpy.zeros_like(pvals) if pvals is a numpy array\n",
    "\n",
    "    # Apply BY correction and assign back to positions\n",
    "    for key in pvals_dict:\n",
    "        pvals_list = pvals_dict[key]\n",
    "        positions = pos_dict[key]\n",
    "        corrected_pvals = false_discovery_control(pvals_list, method='by')\n",
    "        for pos, by_pval in zip(positions, corrected_pvals):\n",
    "            BYpvals[pos] = by_pval\n",
    "\n",
    "    # Add BYpvals to the original data dictionary\n",
    "    data['BYpvals'] = BYpvals\n",
    "\n",
    "    # Now, pvals_dict contains lists of p-values for each unique (method, index) pair"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.622871Z"
    }
   },
   "id": "3e8b6f8b6ae885d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_BY_pval_by_method_and_index(target_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.624123Z"
    }
   },
   "id": "28df5e7794f2fcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Calculating Thresholded Power"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5164ec59ad6b06ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_thresholded_power(pvalue, targets, level, threshold=0.05,\n",
    "                                operator=ge):\n",
    "    pvalue = np.array(pvalue)\n",
    "    targets = np.array(targets)\n",
    "    non_null = operator(np.abs(targets), threshold)\n",
    "    rejection = pvalue < level\n",
    "    if np.sum(non_null) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        true_rej = np.sum(non_null * rejection) / np.sum(non_null)\n",
    "\n",
    "    return true_rej\n",
    "\n",
    "def calculate_thresholded_power_df(targets_dict,\n",
    "                                   threshold=0.1,\n",
    "                                   level=0.1,\n",
    "                                   operator=ge, \n",
    "                                   pval_key = \"BYpvals\"):\n",
    "    grouped_targets = pd.DataFrame(targets_dict).groupby(['index',\n",
    "                                                          'method', 'parameter'])\n",
    "    power_df = {}\n",
    "    power_df['parameter'] = []\n",
    "    power_df['method'] = []\n",
    "    power_df['thresholded power'] = []\n",
    "    for name, group in grouped_targets:\n",
    "        power_df['parameter'].append(name[2])\n",
    "        power_df['method'].append(name[1])\n",
    "        pvalues = group[pval_key]\n",
    "        targets = group['target']\n",
    "        power_df['thresholded power'].append(\n",
    "            calculate_thresholded_power(pvalues, targets, level=level, \n",
    "                                        threshold=threshold, operator=operator))\n",
    "    return power_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.625111Z"
    }
   },
   "id": "ee5636dd1467da4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def point_plot_power(oper_char_dfs, x_axis='p', hue='method', \n",
    "                     ylim_low=None, ylim_high=None, exclude_naive=True,\n",
    "                     randomizer_scales=None, x_label=None):\n",
    "    for i in range(len(oper_char_dfs)):\n",
    "        oper_char_dfs[i] = oper_char_dfs[i].copy()\n",
    "        if exclude_naive:\n",
    "            oper_char_dfs[i] = oper_char_dfs[i][oper_char_dfs[i]['method'] != \"Naive\"]\n",
    "    sns.set_style(\"white\", {'axes.facecolor': 'white',\n",
    "                            'axes.grid': True,\n",
    "                            'axes.linewidth': 2.0,\n",
    "                            'grid.linestyle': u'--',\n",
    "                            'grid.linewidth': 4.0,\n",
    "                            'xtick.major.size': 5.0,\n",
    "                            })\n",
    "    # sns.histplot(oper_char_df[\"sparsity size\"])\n",
    "    # plt.show()\n",
    "    n_subplots = len(oper_char_dfs)\n",
    "    # cols = int(np.ceil(n_subplots / 2))\n",
    "    cols = n_subplots\n",
    "\n",
    "    fig = plt.figure(figsize=(cols * 5, 6))\n",
    "\n",
    "    my_palette = {\"MLE\": \"#48c072\",\n",
    "                  \"Naive\": \"#fc5a50\",\n",
    "                  \"Data Splitting\": \"#03719c\"}\n",
    "\n",
    "    # Create each subplot\n",
    "    for i in range(1, n_subplots + 1):\n",
    "        # ax = fig.add_subplot(2, cols, i) #two rows\n",
    "        ax = fig.add_subplot(1, cols, i)  # one row\n",
    "        if hue is not None:\n",
    "            sns.pointplot(x=oper_char_dfs[i-1][x_axis],\n",
    "                          y=oper_char_dfs[i-1]['thresholded power'],\n",
    "                          hue=oper_char_dfs[i-1][hue],\n",
    "                          markers='o',\n",
    "                          palette=my_palette,\n",
    "                          ax=ax)\n",
    "            ax.set_title(\"Randomizer Scale:\" + str(randomizer_scales[i-1]))\n",
    "        else:\n",
    "            sns.pointplot(x=oper_char_dfs[i-1][x_axis],\n",
    "                          y=oper_char_dfs[i-1]['thresholded power'],\n",
    "                          markers='o',\n",
    "                          palette=my_palette,\n",
    "                          ax=ax)\n",
    "        if ylim_low is not None and ylim_high is not None:\n",
    "            ax.set_ylim([ylim_low, ylim_high])\n",
    "\n",
    "        ax.legend().set_visible(False)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # fig.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.2)\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.3)\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=n_subplots,\n",
    "               prop={'size': 15})\n",
    "\n",
    "    # cov_plot.legend_.remove()\n",
    "    # len_plot.legend_.remove()\n",
    "\n",
    "    # plt.suptitle(\"Changing n,p\")\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.5)\n",
    "    if x_label is not None:\n",
    "        plt.xlabel(x_label)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.626119Z"
    }
   },
   "id": "2e3526c8da48b287"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "power_threshold = 1\n",
    "power_df1 = calculate_thresholded_power_df(targets_dict=target_dict, \n",
    "                                           threshold=power_threshold, level=0.1,\n",
    "                                           operator=ge, pval_key=\"BYpvals\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.627130Z"
    }
   },
   "id": "1bd2c302e6fe1ff3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "point_plot_power(oper_char_dfs=[pd.DataFrame(power_df1)],\n",
    "                 x_axis=\"parameter\",\n",
    "                 hue=\"method\", ylim_high=0.1, ylim_low=0,\n",
    "                 randomizer_scales=[\"Hessian\"], exclude_naive=False,\n",
    "                 x_label=\"Split ratio (r)\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.628113Z"
    }
   },
   "id": "571eacda73c08e58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_palette = {\"MLE\": \"#48c072\",\n",
    "                  \"Naive\": \"#fc5a50\",\n",
    "                  \"Data Splitting\": \"#03719c\"}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.629187Z"
    }
   },
   "id": "d699e9292694f9bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(power_df1)\n",
    "#df = df[df[\"method\"] != \"Naive\"]\n",
    "sns.pointplot(x=df[\"parameter\"],\n",
    "              y=df[\"thresholded power\"],\n",
    "              hue=df[\"method\"], markers='o',\n",
    "              palette=my_palette)\n",
    "plt.xlabel(\"Split ratio (r)\")\n",
    "plt.ylabel(\"Thresholded Power\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.630110Z"
    }
   },
   "id": "5a2eb2324d583213"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "power_threshold = 1\n",
    "FDP_df1 = calculate_thresholded_power_df(targets_dict=target_dict,\n",
    "                                           threshold=power_threshold, level=0.1,\n",
    "                                           operator=le, pval_key=\"BYpvals\")\n",
    "point_plot_power(oper_char_dfs=[pd.DataFrame(FDP_df1)],\n",
    "                 x_axis=\"parameter\",\n",
    "                 hue=\"method\", ylim_high=0.1, ylim_low=0,\n",
    "                 randomizer_scales=[\"Hessian\"], exclude_naive=False,\n",
    "                 x_label=\"Split ratio (r)\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.631151Z"
    }
   },
   "id": "d3e406e0bdab01ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-12T07:12:06.632187Z"
    }
   },
   "id": "71cec8c4272dfc25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
